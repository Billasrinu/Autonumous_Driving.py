#  1. Import Dependencies
import gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.evaluation import evaluate_policy
import os 
# 2. Create & Test Environment
environment_name = "CarRacing-v2"
env = gym.make(environment_name,render_mode='rgb_array')
print(env.action_space)
print(env.observation_space)
### Testing the environment
episodes = 2
for episode in range(1, episodes+1):
    obs=env.reset()
    done=False
    score=0

    while not done:
        env.render()
        action=env.action_space.sample()
        obs, reward, terminated, truncated, info=env.step(action)
        score+=reward
    print(f'score={score}, Episode{episode}')
env.close()

# 3. Train Model
log_path = os.path.join('Training', 'Logs')
env=DummyVecEnv([lambda:env])
env = DummyVecEnv(env,n_stack=4)
model = PPO("CnnPolicy", env, verbose=1, tensorboard_log=log_path)
model.learn(total_timesteps=10)
# 4 Save Model
ppo_path = os.path.join('Training', 'Saved Models', 'PPO_Driving_model')
model.save(ppo_path)
## Loading the model
# # model = PPO.load(ppo_path, env)

# 5. Evaluate and Test
evaluate_policy(model, env, n_eval_episodes=10, render=True)
env.close()
obs = env.reset()
while True:
    action, _states = model.predict(obs)
    obs, reward, terminated, truncated, info=env.step(action)
    env.render()
env.close()
